{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245725e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a709af91",
   "metadata": {},
   "source": [
    "# 모폴로지 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e7785",
   "metadata": {},
   "source": [
    "## 침식과 팽창"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4827b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./data/milkdrop.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "thresh, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "erode = cv2.erode(src_bin, None)\n",
    "dilate = cv2.dilate(src_bin, None)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_bin', src_bin)\n",
    "cv2.imshow('erode', erode)\n",
    "cv2.imshow('dilate', dilate)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d288f",
   "metadata": {},
   "source": [
    "## 열기와 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71dda44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./data/milkdrop.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "thresh, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "# 열기 : 침식 -> 팽창\n",
    "opening = cv2.morphologyEx(src_bin, cv2.MORPH_OPEN, None, iterations = 1)\n",
    "\n",
    "# 닫기 : 팽창 -> 침식\n",
    "closing = cv2.morphologyEx(src_bin, cv2.MORPH_CLOSE, None, iterations = 1)\n",
    "\n",
    "\n",
    "#cv2.imshow('src', src)\n",
    "cv2.imshow('src_bin', src_bin)\n",
    "cv2.imshow('opening', opening)\n",
    "cv2.imshow('closing', closing)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d09f46",
   "metadata": {},
   "source": [
    "# 레이블링과 외곽선 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1982a1c9",
   "metadata": {},
   "source": [
    "## 레이블링 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ccb6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[0 0 1 1 0 0 0 0]\n",
      " [1 1 1 1 0 0 2 0]\n",
      " [1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 3 3 0]\n",
      " [0 0 0 3 3 3 3 0]\n",
      " [0 0 0 3 0 0 3 0]\n",
      " [0 0 3 3 3 3 3 0]\n",
      " [0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "src = np.array([[0, 0, 1, 1, 0, 0, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0, 1, 0],\n",
    "                [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 1, 0],\n",
    "                [0, 0, 0, 1, 1, 1, 1, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 1, 0],\n",
    "                [0, 0, 1, 1, 1, 1, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0]]).astype(np.uint8)\n",
    "\n",
    "src = src * 255\n",
    "cnt, labels = cv2.connectedComponents(src)\n",
    "\n",
    "print(cnt)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e67fac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./data/circles.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "thresh, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "cnt, labels = cv2.connectedComponents(src_bin)\n",
    "\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR) # 객체별로 색깔을 다르게 표시할 3차원 도화지 준비\n",
    "\n",
    "dst[labels == 0] = (0, 255, 255) # 배경은 노란색으로 설정\n",
    "dst[labels == 1] = (0, 0, 255) # 1번 객체는 빨간색으로 설정\n",
    "dst[labels == 2] = (255, 0, 255) # 2번 객체는 보라색으로 설정\n",
    "dst[labels == 3] = (0, 255, 0) # 3번 객체는 초록색으로 설정\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_bin', src_bin)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ab092",
   "metadata": {},
   "source": [
    "## 레이블링 응용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30596cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./data/circles.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "thresh, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(src_bin)\n",
    "\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR) # 객체별로 색깔을 다르게 표시할 3차원 도화지 준비\n",
    "\n",
    "for i in range(1, cnt): # 객체 1, 2, 3\n",
    "    b = np.random.randint(0, 256)\n",
    "    g = np.random.randint(0, 256)\n",
    "    r = np.random.randint(0, 256)\n",
    "    dst[labels == i] = (b, g, r)\n",
    "    \n",
    "    # bounding box --> rectangle\n",
    "    x, y, width, height, area = stats[i]\n",
    "    cv2.rectangle(dst, (x, y), (x+width, y+height), (0, 0, 255))\n",
    "    \n",
    "    # centroids --> circle\n",
    "    cx, cy = centroids[i]\n",
    "    cv2.circle(dst, (int(cx), int(cy)), 5, (255, 0, 0), -1)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_bin', src_bin)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2758ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./data/keyboard.bmp') # BGR 3 채널 데이터\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh, src_bin = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(src_bin)\n",
    "\n",
    "dst = src.copy() # BGR 3 채널 도화지\n",
    "\n",
    "for i in range(1, cnt): # 0번 배경은 제회, 1~37번 객체\n",
    "    x, y, width, height, area = stats[i]\n",
    "    if area > 20:\n",
    "        cv2.rectangle(dst, (x, y), (x+width, y+height), (0, 255, 255))\n",
    "    \n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_bin', src_bin)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1beb3",
   "metadata": {},
   "source": [
    "## 외곽선 검출과 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f180655",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./data/contours.bmp')\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "thresh, gray_bin = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "dst = src.copy()\n",
    "contours, hierarchy = cv2.findContours(gray_bin, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for i in range(len(contours)): # 9 iterations\n",
    "    b = np.random.randint(0, 256)\n",
    "    g = np.random.randint(0, 256)\n",
    "    r = np.random.randint(0, 256)\n",
    "    cv2.drawContours(dst, contours, i, (b, g, r), 2)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0cd52107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "src = cv2.imread('./data/thumbs_up_down.jpg')\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh, gray_bin = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(gray_bin, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "print(len(contours))\n",
    "\n",
    "dst = src.copy()\n",
    "cv2.drawContours(dst, contours, -1, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('gray', gray)\n",
    "cv2.imshow('gray_bin', gray_bin)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4c8618b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 왼손만 bounding box 그리기\n",
    "# left_hand = contours[1] # 왼손을 둘러싸는 점의 좌표들\n",
    "# x, y, width, height = cv2.boundingRect(left_hand)\n",
    "\n",
    "# 오른손만 bounding box 그리기\n",
    "right_hand = contours[0] # 왼손을 둘러싸는 점의 좌표들\n",
    "x, y, width, height = cv2.boundingRect(right_hand)\n",
    "\n",
    "\n",
    "dst2 = src.copy()\n",
    "\n",
    "cv2.rectangle(dst2, (x, y), (x+width, y+height), (0, 255, 255), 3)\n",
    "\n",
    "cv2.imshow('dst2', dst2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2a15b",
   "metadata": {},
   "source": [
    "# 객체 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c389697",
   "metadata": {},
   "source": [
    "## 캐스케이스 분류기와 얼굴 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2698b",
   "metadata": {},
   "source": [
    "**opencv**\n",
    "https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html\n",
    "\n",
    "**haar cascade classifier**\n",
    "https://towardsdatascience.com/viola-jones-algorithm-and-haar-cascade-classifier-ee3bfb19f7d8\n",
    "\n",
    "https://webnautes.tistory.com/1352 (한글 블로그)\n",
    "\n",
    "**adaboost**\n",
    "https://www.youtube.com/watch?v=LsK-xG1cLYA (유튜브)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e6ef79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./data/lena.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "for face in faces:\n",
    "    x, y, w, h = face\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('image', image)    \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "30d67f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./data/kids2.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./data/haarcascade_eye.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "for face in faces:\n",
    "    x, y, w, h = face\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    face_rect = image[y:y+h, x:x+w]    \n",
    "    eyes = eye_cascade.detectMultiScale(face_rect)\n",
    "    \n",
    "    for eye in eyes:\n",
    "        x1, y1, w1, h1 = eye\n",
    "        cv2.rectangle(face_rect, (x1, y1), (x1+w1, y1+h1), (255, 0, 0), 2)\n",
    "        \n",
    "\n",
    "cv2.imshow('image', image)    \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df69bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detectMultiScale\n",
    "# scaleFactor : 검색 윈도우 확대 비율 (default =1.1)\n",
    "# minNeighbors : 검출 영역으로 선택하기 위한 최소 검출 횟수 (default = 3)\n",
    "# minSize : 검출할 객체의 최소크기\n",
    "# maxSize : 검출할 객체의 최대크기\n",
    "\n",
    "# scaleFactor가 detect시 미치는 영향\n",
    "# https://answers.opencv.org/question/10654/how-does-the-parameter-scalefactor-in-detectmultiscale-affect-face-detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c3490df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./data/multi_faces.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_casecade = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "#faces = face_casecade.detectMultiScale(gray, 1.3, 8)\n",
    "#faces = face_casecade.detectMultiScale(gray, minSize=(100, 100), maxSize=(130, 130))\n",
    "faces = face_casecade.detectMultiScale(gray, scaleFactor=2, minNeighbors=5)\n",
    "\n",
    "for face in faces:\n",
    "    x, y, w, h = face\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('image', image)    \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe1d48",
   "metadata": {},
   "source": [
    "## HOG 알고리즘과 보행자 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83243aa5",
   "metadata": {},
   "source": [
    "**HOG Descriptor**\n",
    "https://docs.opencv.org/4.x/d5/d33/structcv_1_1HOGDescriptor.html#a723b95b709cfd3f95cf9e616de988fc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5f04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f544c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee2123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
